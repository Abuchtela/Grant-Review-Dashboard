{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb14571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import pytz\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a486bf1",
   "metadata": {},
   "source": [
    "# intro "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178657db",
   "metadata": {},
   "source": [
    "This notebook is part of the construction of the Github Activity Lego , it contains the construction of a module that : \n",
    "\n",
    "- accepts a series of github projects URL; \n",
    "\n",
    "- uses the github API to get data about the  project interactions given a specific timeframe ( here we used the first week of  Gitcoin Grants Round 15 and 6 months back from that week. So, from week 14 till week 38 of 2022).\n",
    "\n",
    "- Returns 3 dataframes by the end:\n",
    "     - github_addittions: additions pushed to the repo by week for each of the repo\n",
    "     \n",
    "     - github_deletions: deletions pushed to the repo by week for each of the repo\n",
    "     \n",
    "\t - raw dataframe : containing the repo information, the status code of the extraction of data form the Github API and the json with the whole data for that repo\n",
    "     \n",
    "\n",
    "It will be used on the extraction of grantees project data to investigate fraudulent behavior on the construction of these repo.Feel free to reach to us for contributions and to tell us about your analyses results :) \n",
    "\n",
    "It was build by stefi_says#1654 and Gray#3751, please reach us on discord for any doubt \n",
    "\n",
    "\n",
    "### Some important information and further development:\n",
    "\n",
    "- You will need a PAT ( personal authorization token) or other authorization key, for more information , check this page of the [documentation](https://docs.github.com/en/rest/guides/getting-started-with-the-rest-api?apiVersion=2022-11-28).  \n",
    "\n",
    "- Even though the PAT was added to it,  it was only possible to make 60 calls a hour , it's our desire to figure out how to amplify that . \n",
    "\n",
    "- Be aware that the APi does not delivers data to deleted repo, so by the end of the process the repo will show on the raw dataframe but with \"extrat_status_code\" =  404 and a json containing the error explanation on \"repo_data\".  \n",
    "\n",
    "- The code is built to break if you reach the rate limit and receives back the \"status_code\" = 403, but it seems to be not respecting that and run forever. That's another improvement to be done.  We advise to break the functions in a scrip and run it in small batches. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facd6feb",
   "metadata": {},
   "source": [
    "# importing data - exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5e13ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grants = pd.read_excel('gr15_grants.xlsx')\n",
    "\n",
    "gr_aplic = pd.read_json('grants_applications_gr15.json').T\n",
    "\n",
    "df  = gr_aplic.merge(grants, on = 'grant_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db7f5e63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['grant_id', 'active_x', 'approved', 'address_x', 'title_x', 'url',\n",
       "       'description_x', 'created_on_x', 'active_y', 'title_y', 'address_y',\n",
       "       'amount_received', 'amount_received_in_round', 'contribution_count',\n",
       "       'contributor_count', 'description_y', 'website', 'github_project_url',\n",
       "       'twitter_handle_2', 'twitter_handle_1', 'twitter_verified',\n",
       "       'created_on_y', 'last_update'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8d628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107eade",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "395a8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# getting the repo data , return a json with the additions, deletions and week on timestamp\n",
    "\n",
    "def github_code_stats( owner, repo, authorization_token):\n",
    "    url = \"https://api.github.com/repos/{owner}/{repo}/stats/code_frequency\"\n",
    "    headers = {\n",
    "     'X-GitHub-Api-Version': '2022-11-28', \n",
    "     'accept':'application/vnd.github+json', \n",
    "     'Authorization': authorization_token\n",
    "     }\n",
    "    \n",
    "\n",
    "    return { 'status_code':requests.get(url.format(owner=owner, repo=repo), headers=headers).status_code , \n",
    "            'repo_data' : requests.get(url.format(owner=owner, repo=repo), headers=headers).json()}\n",
    "\n",
    "\n",
    "\n",
    "#-----------------\n",
    "# get the owner and the repo name of a list of projects github urls\n",
    "#used in the pipline\n",
    "#function return a df\n",
    "# acepts URLS give back a df with URL / owner of the repo / Repo name\n",
    "# does not work with None values\n",
    "\n",
    "def get_owner_repo(github_urls):\n",
    "\n",
    "    owner = []\n",
    "    repo = []\n",
    "    url = []\n",
    "\n",
    "    for i in github_urls:\n",
    "        matches = re.search(r\"github\\.com\\/([\\w\\-\\.]+)\\/([\\w\\-\\.]+)\", i)\n",
    "        if matches:\n",
    "            username = matches.group(1)\n",
    "            repository_name = matches.group(2)\n",
    "            url.append(i)\n",
    "            owner.append(username)\n",
    "            repo.append(repository_name)\n",
    "        else:\n",
    "            matches = re.search(r\"github\\.com\\/([\\w\\-\\.]+)\", i)\n",
    "            if matches:\n",
    "                owner_name = matches.group(1)\n",
    "                url.append(i)\n",
    "                owner.append(owner_name)\n",
    "                repo.append(None)\n",
    "            else:\n",
    "                url.append(i)\n",
    "                owner.append(None)\n",
    "                repo.append(None)\n",
    "\n",
    "    github_owner_repo = pd.DataFrame(data= {'url': url, 'owner': owner, 'repo': repo})\n",
    "    return github_owner_repo\n",
    "    \n",
    "#------------------------\n",
    "# funtions acepts df with owner repo name, owner, url to the repo and spits off a dataframe with that informationd and add data of aditions and deletions of that repo in a json \n",
    "\n",
    "\n",
    "def retrive_git_data(owner_repo_names, authorization_token):\n",
    "    \n",
    "        column_names = ['url', 'owner', 'repo', 'extract_status_code', 'repo_data']\n",
    "        git_data  = pd.DataFrame([],columns = column_names)\n",
    "\n",
    "        for i in range(0,len(owner_repo_names['owner'])):\n",
    "                # gettin owner and repo\n",
    "                git_owner = owner_repo_names.iloc[i]['owner']\n",
    "                git_repo = owner_repo_names.iloc[i]['repo']\n",
    "\n",
    "                # pocking the APi to start gathering the stats\n",
    "                git_extract = github_code_stats(git_owner, git_repo, authorization_token)\n",
    "                data = [{'url' : owner_repo_names.iloc[i]['url'], 'owner' : git_owner, 'repo' : git_repo,  'extract_status_code': \n",
    "                        git_extract['status_code'] , 'repo_data': git_extract['repo_data']}]\n",
    "                df = pd.DataFrame(data = data)\n",
    "                \n",
    "                git_data = pd.concat([git_data, df])\n",
    "\n",
    "\n",
    "        git_data.set_index('url', inplace = True)\n",
    "\n",
    "        while git_data['extract_status_code'].isin([202]).sum() != 0:\n",
    "\n",
    "            time.sleep(20)\n",
    "\n",
    "            redo_df = git_data[git_data['extract_status_code'] == 202].reset_index().copy()\n",
    "            for i in range(len(redo_df)):\n",
    "\n",
    "                redo_owner = redo_df.loc[i, 'owner']\n",
    "                redo_repo = redo_df.loc[i, 'repo']\n",
    "\n",
    "                git_extract = github_code_stats(redo_owner, redo_repo, authorization_token)\n",
    "\n",
    "                if (git_extract['status_code'] != 403):\n",
    "\n",
    "                    git_data.at[redo_df['url'][i], 'extract_status_code'] = git_extract['status_code']\n",
    "                    git_data.at[redo_df['url'][i], 'repo_data'] = git_extract['repo_data']\n",
    "\n",
    "                else:\n",
    "\n",
    "                    break\n",
    "\n",
    "\n",
    "        return git_data\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# function used inside 'timeframing_data' to get the time stamp of the sunday of a given week by its number\n",
    "# its used to filter the start and finish of the period to colect the data \n",
    "\n",
    "def sunday_timestamp(week_number, year):\n",
    "    # Create a datetime object for the first day of the given year\n",
    "    first_day = datetime.datetime(year, 1, 1, tzinfo=pytz.utc)\n",
    "    \n",
    "    # Calculate the number of days to the first Sunday of the year\n",
    "    days_to_first_sunday = (6 - first_day.weekday()) % 7\n",
    "    \n",
    "    # Calculate the number of days to the Sunday of the given week\n",
    "    days_to_sunday = (week_number - 1) * 7 + days_to_first_sunday\n",
    "    \n",
    "    # Create a datetime object for the Sunday of the given week\n",
    "    sunday = first_day + datetime.timedelta(days=days_to_sunday)\n",
    "    \n",
    "    # Convert the datetime object to a UTC timestamp\n",
    "    return int(sunday.timestamp())\n",
    "\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# function to treat the json data generated by github_code_stats retunrs a datafram with the url/weeks/ additons or deletion per week on that repo\n",
    "# repo_data must be in json \n",
    "# start and end date aggregation in week number \n",
    "# year number like 'yyyy' = '2023'\n",
    "\n",
    "def timeframing_data(repo_data, start_date_aggregation, end_date_aggregation, year_to_start, year_to_finish):\n",
    "    weeks = []\n",
    "    addition = []\n",
    "    deletions = []\n",
    "\n",
    "    for i in range(len(repo_data)):\n",
    "        weeks.append(repo_data[i][0])\n",
    "        addition.append(repo_data[i][1])\n",
    "        deletions.append(repo_data[i][2])\n",
    "\n",
    "\n",
    "    week_addition = pd.DataFrame( data = [weeks, addition, deletions]).T\n",
    "\n",
    "    week_addition.columns = ['weeks', 'addition', 'deletions']\n",
    "\n",
    "    additions_by_week = week_addition[(week_addition['weeks']<= sunday_timestamp(start_date_aggregation,year_to_start)) & \n",
    "                  (week_addition['weeks'] >= ((sunday_timestamp(end_date_aggregation,year_to_finish) )))]\n",
    "    \n",
    "    return additions_by_week\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# receives df with repo name, owner, url and json of the data and spits two df, addtions by url and deletions by url given a timeframe\n",
    "def tretened_df(raw_git_data, start_date_aggregation, end_date_aggregation, year_to_start,year_to_finish ):\n",
    "\n",
    "    addtions_df  = pd.DataFrame([])\n",
    "\n",
    "\n",
    "    deletions_df  = pd.DataFrame([])\n",
    "\n",
    "    valid_git_data = raw_git_data[raw_git_data['extract_status_code'] == 200]\n",
    "    for i in range(0,(len(valid_git_data)-1)):\n",
    "        timeframed_df = timeframing_data(valid_git_data['repo_data'][i], \n",
    "                                         start_date_aggregation, \n",
    "\n",
    "                                        end_date_aggregation, \n",
    "                                         year_to_start , \n",
    "                                         year_to_finish )\n",
    "\n",
    "        ad_df = timeframed_df[['weeks','addition']].T\n",
    "        ad_df.columns=ad_df.iloc[0] \n",
    "        ad_df.drop(labels='weeks', inplace = True)\n",
    "        ad_df.rename(index = {'addition' :valid_git_data.index[i]}, inplace = True)\n",
    "        addtions_df= pd.concat([addtions_df, ad_df])\n",
    "\n",
    "        del_df = timeframed_df[['weeks','deletions']].T\n",
    "        del_df.columns=del_df.iloc[0] \n",
    "        del_df.drop(labels='weeks', inplace = True)\n",
    "        del_df.rename(index = {'deletions' :valid_git_data.index[i]}, inplace = True)\n",
    "        deletions_df= pd.concat([deletions_df, del_df])\n",
    "\n",
    "    return addtions_df , deletions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f8ef0",
   "metadata": {},
   "source": [
    "## final pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c80a46c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def repo_additions_deletion(url_repo_series,start_date_aggregation,end_date_aggregation,year_to_start, year_to_finish, authorization_token ):\n",
    "    # from a list get the owner and repo names\n",
    "    owner_repo_names  = get_owner_repo(url_repo_series)\n",
    "\n",
    "    #cleaning the none values, dealing with index issues\n",
    "    owner_repo_names = owner_repo_names[~owner_repo_names['repo'].isna()]\n",
    "    owner_repo_names = owner_repo_names[owner_repo_names['repo'] != '']\n",
    "    owner_repo_names = owner_repo_names.drop(owner_repo_names[owner_repo_names.duplicated()].index)\n",
    "    owner_repo_names.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "    #  pocking waiting and getting the data from the API. returnin repo infos and raw json with all weeks and add and dels by week timestamp\n",
    "    raw_git_data = retrive_git_data(owner_repo_names, authorization_token)\n",
    "\n",
    "    # treats the data to the dates we specifyed and gives back the addtions and deletions data frame together with the raw dataframe\n",
    "\n",
    "    return tretened_df(raw_git_data, start_date_aggregation, end_date_aggregation, year_to_start,year_to_finish ) , raw_git_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e94f90",
   "metadata": {},
   "source": [
    "# applying the final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be67165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_repo_series =  df[160:175]['github_project_url']\n",
    "url_repo_series = url_repo_series[~url_repo_series.isna()]\n",
    "\n",
    "authorization_token = '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'\n",
    "\n",
    "start_date_aggregation = 36 #  September 7 started the GR15 round\n",
    "end_date_aggregation = 12 # 6 months back\n",
    "\n",
    "year_to_start = 2022\n",
    "year_to_finish = 2022\n",
    "\n",
    "x1, x2 = repo_additions_deletion(url_repo_series,\n",
    "                        start_date_aggregation,\n",
    "                        end_date_aggregation,\n",
    "                        year_to_start,\n",
    "                        year_to_finish, \n",
    " \n",
    "                        authorization_token )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80361a",
   "metadata": {},
   "source": [
    "## final dataframes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada6df6",
   "metadata": {},
   "source": [
    "- x1 is a object with two dataframes , the first one containing the 'addtions by week' dataframe of each url, and the second one with the same schema but with the deletions information\n",
    "- Notice that Nan for given weeks mens that the repo does not existed on by that time\n",
    "- x2 would be a dataset containing the url / owner_repo / repo_name / repo_data where repodata is a json with all the data obtaned from the API for that url\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e24b5ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>weeks</th>\n",
       "      <th>1647734400</th>\n",
       "      <th>1648339200</th>\n",
       "      <th>1648944000</th>\n",
       "      <th>1649548800</th>\n",
       "      <th>1650153600</th>\n",
       "      <th>1650758400</th>\n",
       "      <th>1651363200</th>\n",
       "      <th>1651968000</th>\n",
       "      <th>1652572800</th>\n",
       "      <th>1653177600</th>\n",
       "      <th>...</th>\n",
       "      <th>1656806400</th>\n",
       "      <th>1657411200</th>\n",
       "      <th>1658016000</th>\n",
       "      <th>1658620800</th>\n",
       "      <th>1659225600</th>\n",
       "      <th>1659830400</th>\n",
       "      <th>1660435200</th>\n",
       "      <th>1661040000</th>\n",
       "      <th>1661644800</th>\n",
       "      <th>1662249600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://github.com/Barabazs/py-is_ipfs</th>\n",
       "      <td>282.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/TaterDAO/app</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3864.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10603</td>\n",
       "      <td>4131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "      <td>10135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/scallionsteak/sg-full-stack</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4836</td>\n",
       "      <td>19423</td>\n",
       "      <td>109848</td>\n",
       "      <td>64785</td>\n",
       "      <td>103672</td>\n",
       "      <td>48952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "weeks                                           1647734400  1648339200  \\\n",
       "https://github.com/Barabazs/py-is_ipfs               282.0       142.0   \n",
       "https://github.com/TaterDAO/app                        0.0         0.0   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN   \n",
       "\n",
       "weeks                                           1648944000  1649548800  \\\n",
       "https://github.com/Barabazs/py-is_ipfs               179.0        88.0   \n",
       "https://github.com/TaterDAO/app                     1743.0      1735.0   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN   \n",
       "\n",
       "weeks                                           1650153600  1650758400  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                 0.0        72.0   \n",
       "https://github.com/TaterDAO/app                        0.0         0.0   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN   \n",
       "\n",
       "weeks                                           1651363200  1651968000  \\\n",
       "https://github.com/Barabazs/py-is_ipfs               270.0         0.0   \n",
       "https://github.com/TaterDAO/app                       68.0         0.0   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN   \n",
       "\n",
       "weeks                                           1652572800  1653177600  ...  \\\n",
       "https://github.com/Barabazs/py-is_ipfs               127.0       192.0  ...   \n",
       "https://github.com/TaterDAO/app                     3864.0       778.0  ...   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN  ...   \n",
       "\n",
       "weeks                                           1656806400  1657411200  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0   \n",
       "https://github.com/TaterDAO/app                          0           0   \n",
       "https://github.com/scallionsteak/sg-full-stack        4836       19423   \n",
       "\n",
       "weeks                                           1658016000  1658620800  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0   \n",
       "https://github.com/TaterDAO/app                          0           0   \n",
       "https://github.com/scallionsteak/sg-full-stack      109848       64785   \n",
       "\n",
       "weeks                                           1659225600  1659830400  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0   \n",
       "https://github.com/TaterDAO/app                      10603        4131   \n",
       "https://github.com/scallionsteak/sg-full-stack      103672       48952   \n",
       "\n",
       "weeks                                           1660435200  1661040000  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0   \n",
       "https://github.com/TaterDAO/app                          0           0   \n",
       "https://github.com/scallionsteak/sg-full-stack           0           0   \n",
       "\n",
       "weeks                                           1661644800  1662249600  \n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0  \n",
       "https://github.com/TaterDAO/app                        308       10135  \n",
       "https://github.com/scallionsteak/sg-full-stack          35           0  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e66f583b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>weeks</th>\n",
       "      <th>1647734400</th>\n",
       "      <th>1648339200</th>\n",
       "      <th>1648944000</th>\n",
       "      <th>1649548800</th>\n",
       "      <th>1650153600</th>\n",
       "      <th>1650758400</th>\n",
       "      <th>1651363200</th>\n",
       "      <th>1651968000</th>\n",
       "      <th>1652572800</th>\n",
       "      <th>1653177600</th>\n",
       "      <th>...</th>\n",
       "      <th>1656806400</th>\n",
       "      <th>1657411200</th>\n",
       "      <th>1658016000</th>\n",
       "      <th>1658620800</th>\n",
       "      <th>1659225600</th>\n",
       "      <th>1659830400</th>\n",
       "      <th>1660435200</th>\n",
       "      <th>1661040000</th>\n",
       "      <th>1661644800</th>\n",
       "      <th>1662249600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://github.com/Barabazs/py-is_ipfs</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/TaterDAO/app</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-560.0</td>\n",
       "      <td>-811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-643.0</td>\n",
       "      <td>-261.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-695</td>\n",
       "      <td>-231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-190</td>\n",
       "      <td>-6162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/scallionsteak/sg-full-stack</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-8312</td>\n",
       "      <td>-11512</td>\n",
       "      <td>-37065</td>\n",
       "      <td>-45731</td>\n",
       "      <td>-22295</td>\n",
       "      <td>-6367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "weeks                                           1647734400  1648339200  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                -7.0       -57.0   \n",
       "https://github.com/TaterDAO/app                        0.0         0.0   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN   \n",
       "\n",
       "weeks                                           1648944000  1649548800  \\\n",
       "https://github.com/Barabazs/py-is_ipfs               -54.0       -58.0   \n",
       "https://github.com/TaterDAO/app                     -560.0      -811.0   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN   \n",
       "\n",
       "weeks                                           1650153600  1650758400  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                 0.0        -8.0   \n",
       "https://github.com/TaterDAO/app                        0.0         0.0   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN   \n",
       "\n",
       "weeks                                           1651363200  1651968000  \\\n",
       "https://github.com/Barabazs/py-is_ipfs               -44.0         0.0   \n",
       "https://github.com/TaterDAO/app                      -50.0         0.0   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN   \n",
       "\n",
       "weeks                                           1652572800  1653177600  ...  \\\n",
       "https://github.com/Barabazs/py-is_ipfs               -11.0      -144.0  ...   \n",
       "https://github.com/TaterDAO/app                     -643.0      -261.0  ...   \n",
       "https://github.com/scallionsteak/sg-full-stack         NaN         NaN  ...   \n",
       "\n",
       "weeks                                           1656806400  1657411200  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0   \n",
       "https://github.com/TaterDAO/app                          0           0   \n",
       "https://github.com/scallionsteak/sg-full-stack       -8312      -11512   \n",
       "\n",
       "weeks                                           1658016000  1658620800  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0   \n",
       "https://github.com/TaterDAO/app                          0           0   \n",
       "https://github.com/scallionsteak/sg-full-stack      -37065      -45731   \n",
       "\n",
       "weeks                                           1659225600  1659830400  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0   \n",
       "https://github.com/TaterDAO/app                       -695        -231   \n",
       "https://github.com/scallionsteak/sg-full-stack      -22295       -6367   \n",
       "\n",
       "weeks                                           1660435200  1661040000  \\\n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0   \n",
       "https://github.com/TaterDAO/app                          0           0   \n",
       "https://github.com/scallionsteak/sg-full-stack           0           0   \n",
       "\n",
       "weeks                                           1661644800  1662249600  \n",
       "https://github.com/Barabazs/py-is_ipfs                   0           0  \n",
       "https://github.com/TaterDAO/app                       -190       -6162  \n",
       "https://github.com/scallionsteak/sg-full-stack         -20           0  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1a3a14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>repo</th>\n",
       "      <th>extract_status_code</th>\n",
       "      <th>repo_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://github.com/Barabazs/py-is_ipfs</th>\n",
       "      <td>Barabazs</td>\n",
       "      <td>py-is_ipfs</td>\n",
       "      <td>200</td>\n",
       "      <td>[[1646524800, 180, 0], [1647129600, 0, 0], [16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/TaterDAO/app</th>\n",
       "      <td>TaterDAO</td>\n",
       "      <td>app</td>\n",
       "      <td>200</td>\n",
       "      <td>[[1647129600, 22399, -489], [1647734400, 0, 0]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/scallionsteak/sg-full-stack</th>\n",
       "      <td>scallionsteak</td>\n",
       "      <td>sg-full-stack</td>\n",
       "      <td>200</td>\n",
       "      <td>[[1656201600, 129261, -149], [1656806400, 4836...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/RingsNetwork/rings-node</th>\n",
       "      <td>RingsNetwork</td>\n",
       "      <td>rings-node</td>\n",
       "      <td>200</td>\n",
       "      <td>[[1640476800, 685, 0], [1641081600, 432, -167]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        owner           repo  \\\n",
       "url                                                                            \n",
       "https://github.com/Barabazs/py-is_ipfs               Barabazs     py-is_ipfs   \n",
       "https://github.com/TaterDAO/app                      TaterDAO            app   \n",
       "https://github.com/scallionsteak/sg-full-stack  scallionsteak  sg-full-stack   \n",
       "https://github.com/RingsNetwork/rings-node       RingsNetwork     rings-node   \n",
       "\n",
       "                                               extract_status_code  \\\n",
       "url                                                                  \n",
       "https://github.com/Barabazs/py-is_ipfs                         200   \n",
       "https://github.com/TaterDAO/app                                200   \n",
       "https://github.com/scallionsteak/sg-full-stack                 200   \n",
       "https://github.com/RingsNetwork/rings-node                     200   \n",
       "\n",
       "                                                                                        repo_data  \n",
       "url                                                                                                \n",
       "https://github.com/Barabazs/py-is_ipfs          [[1646524800, 180, 0], [1647129600, 0, 0], [16...  \n",
       "https://github.com/TaterDAO/app                 [[1647129600, 22399, -489], [1647734400, 0, 0]...  \n",
       "https://github.com/scallionsteak/sg-full-stack  [[1656201600, 129261, -149], [1656806400, 4836...  \n",
       "https://github.com/RingsNetwork/rings-node      [[1640476800, 685, 0], [1641081600, 432, -167]...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0af5b7",
   "metadata": {},
   "source": [
    "# analysis tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc674f",
   "metadata": {},
   "source": [
    "Merge a 'flag' column from the original dataset  and use this  data to do some data anylisis and extract info form some supervised learning algos like:\n",
    " \n",
    " - logistic regression on the rejected grants about the most active weeks before the start of the subscription\n",
    " \n",
    " - overal comparison between activity level between approved and rejected grants \n",
    " \n",
    " - distribution of activity given time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db62a7f",
   "metadata": {},
   "source": [
    "# retriving in small bacthes given API Rate Limit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f7118",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbe3588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_urls  = df['github_project_url'].dropna()\n",
    "valid_urls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78caab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_repo_series =  valid_urls[130:155]\n",
    "url_repo_series = url_repo_series[~url_repo_series.isna()]\n",
    "authorization_token = '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'\n",
    "start_date_aggregation = 38\n",
    "end_date_aggregation = 14\n",
    "year_to_start = 2022\n",
    "year_to_finish = 2022\n",
    "\n",
    "owner_repo_names  = get_owner_repo(url_repo_series)\n",
    "\n",
    "#cleaning the none values\n",
    "owner_repo_names = owner_repo_names[~owner_repo_names['repo'].isna()]\n",
    "owner_repo_names = owner_repo_names[owner_repo_names['repo'] != '']\n",
    "\n",
    "owner_repo_names = owner_repo_names.drop(owner_repo_names[owner_repo_names.duplicated()].index)\n",
    "owner_repo_names.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00801143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>owner</th>\n",
       "      <th>repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/relational-os/rlog</td>\n",
       "      <td>relational-os</td>\n",
       "      <td>rlog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/0xperp/defi_greeks</td>\n",
       "      <td>0xperp</td>\n",
       "      <td>defi_greeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/regen-foundation/gr15-easta...</td>\n",
       "      <td>regen-foundation</td>\n",
       "      <td>gr15-eastafrica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url             owner  \\\n",
       "0              https://github.com/relational-os/rlog     relational-os   \n",
       "1              https://github.com/0xperp/defi_greeks            0xperp   \n",
       "2  https://github.com/regen-foundation/gr15-easta...  regen-foundation   \n",
       "\n",
       "              repo  \n",
       "0             rlog  \n",
       "1      defi_greeks  \n",
       "2  gr15-eastafrica  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owner_repo_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ccd923e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28060\\2299158154.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# here should come the function we are developing down here, it should receibe the variable owner_repo_name adn spits out a df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mraw_git_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrive_git_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mowner_repo_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthorization_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mraw_git_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28060\\1368925825.py\u001b[0m in \u001b[0;36mretrive_git_data\u001b[1;34m(owner_repo_names, authorization_token)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[1;31m# pocking the APi to start gathering the stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mgit_extract\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgithub_code_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgit_owner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgit_repo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthorization_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                 data = [{'url' : owner_repo_names.iloc[i]['url'], 'owner' : git_owner, 'repo' : git_repo,  'extract_status_code': \n\u001b[0;32m    132\u001b[0m                         git_extract['status_code'] , 'repo_data': git_extract['repo_data']}]\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28060\\1368925825.py\u001b[0m in \u001b[0;36mgithub_code_stats\u001b[1;34m(owner, repo, authorization_token)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     return { 'status_code':requests.get(url.format(owner=owner, repo=repo), headers=headers).status_code , \n\u001b[1;32m---> 13\u001b[1;33m             'repo_data' : requests.get(url.format(owner=owner, repo=repo), headers=headers).json()}\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[1;31m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m             \u001b[1;31m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# here should come the function we are developing down here, it should receibe the variable owner_repo_name adn spits out a df\n",
    "raw_git_data = retrive_git_data(owner_repo_names, authorization_token)\n",
    "\n",
    "raw_git_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f880fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_git_data = raw_git_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_git_data.to_csv('raw_git_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b06f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
